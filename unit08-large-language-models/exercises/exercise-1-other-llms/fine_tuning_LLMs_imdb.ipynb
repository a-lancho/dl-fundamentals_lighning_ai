{"cells":[{"cell_type":"markdown","metadata":{"id":"3c5d72f4"},"source":["# Finetuning a DistilBERT Classifier in Lightning"]},{"cell_type":"markdown","metadata":{"id":"0873756d-262a-4525-b809-4e0b3a1e63dd"},"source":["![](figures/finetuning-ii.png)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14481,"status":"ok","timestamp":1689648786614,"user":{"displayName":"ALEJANDRO LANCHO SERRANO","userId":"06980355390280053762"},"user_tz":240},"id":"oFhDouBQrauK","outputId":"0b657cdb-113d-4161-f86b-c1b34162e91e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: watermark in /usr/local/lib/python3.10/dist-packages (2.4.3)\n","Requirement already satisfied: ipython\u003e=6.0 in /usr/local/lib/python3.10/dist-packages (from watermark) (7.34.0)\n","Requirement already satisfied: importlib-metadata\u003e=1.4 in /usr/local/lib/python3.10/dist-packages (from watermark) (6.8.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from watermark) (67.7.2)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata\u003e=1.4-\u003ewatermark) (3.16.1)\n","Requirement already satisfied: jedi\u003e=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython\u003e=6.0-\u003ewatermark) (0.18.2)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython\u003e=6.0-\u003ewatermark) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython\u003e=6.0-\u003ewatermark) (0.7.5)\n","Requirement already satisfied: traitlets\u003e=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython\u003e=6.0-\u003ewatermark) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,\u003c3.1.0,\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython\u003e=6.0-\u003ewatermark) (3.0.39)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython\u003e=6.0-\u003ewatermark) (2.14.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython\u003e=6.0-\u003ewatermark) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython\u003e=6.0-\u003ewatermark) (0.1.6)\n","Requirement already satisfied: pexpect\u003e4.3 in /usr/local/lib/python3.10/dist-packages (from ipython\u003e=6.0-\u003ewatermark) (4.8.0)\n","Requirement already satisfied: parso\u003c0.9.0,\u003e=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi\u003e=0.16-\u003eipython\u003e=6.0-\u003ewatermark) (0.8.3)\n","Requirement already satisfied: ptyprocess\u003e=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect\u003e4.3-\u003eipython\u003e=6.0-\u003ewatermark) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,\u003c3.1.0,\u003e=2.0.0-\u003eipython\u003e=6.0-\u003ewatermark) (0.2.6)\n"]}],"source":["!pip install watermark"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17530,"status":"ok","timestamp":1689648804141,"user":{"displayName":"ALEJANDRO LANCHO SERRANO","userId":"06980355390280053762"},"user_tz":240},"id":"6fd9cda8","outputId":"8643c4ee-6362-4dbc-b60a-aedefeb02ed3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: tokenizers!=0.11.3,\u003c0.14,\u003e=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: safetensors\u003e=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.14.1-\u003etransformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.14.1-\u003etransformers) (4.7.1)\n","Requirement already satisfied: urllib3\u003c1.27,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers) (1.26.16)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers) (2.0.12)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers) (3.4)\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16479,"status":"ok","timestamp":1689648820610,"user":{"displayName":"ALEJANDRO LANCHO SERRANO","userId":"06980355390280053762"},"user_tz":240},"id":"92ea5612","outputId":"d4ae7089-c0a0-4e16-9e70-12db76b77db1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.13.1)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n","Requirement already satisfied: pyarrow\u003e=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: dill\u003c0.3.7,\u003e=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests\u003e=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n","Requirement already satisfied: tqdm\u003e=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.2.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.14)\n","Requirement already satisfied: fsspec[http]\u003e=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n","Requirement already satisfied: huggingface-hub\u003c1.0.0,\u003e=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.16.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer\u003c4.0,\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (2.0.12)\n","Requirement already satisfied: multidict\u003c7.0,\u003e=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (6.0.4)\n","Requirement already satisfied: async-timeout\u003c5.0,\u003e=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (4.0.2)\n","Requirement already satisfied: yarl\u003c2.0,\u003e=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (1.9.2)\n","Requirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (1.4.0)\n","Requirement already satisfied: aiosignal\u003e=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (1.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0.0,\u003e=0.11.0-\u003edatasets) (3.12.2)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0.0,\u003e=0.11.0-\u003edatasets) (4.7.1)\n","Requirement already satisfied: urllib3\u003c1.27,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.19.0-\u003edatasets) (1.26.16)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.19.0-\u003edatasets) (2023.5.7)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.19.0-\u003edatasets) (3.4)\n","Requirement already satisfied: python-dateutil\u003e=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas-\u003edatasets) (2.8.2)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas-\u003edatasets) (2022.7.1)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil\u003e=2.8.1-\u003epandas-\u003edatasets) (1.16.0)\n"]}],"source":["!pip install datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18631,"status":"ok","timestamp":1689648839232,"user":{"displayName":"ALEJANDRO LANCHO SERRANO","userId":"06980355390280053762"},"user_tz":240},"id":"fe7191cf-62ed-4793-8358-bee70b233d05","outputId":"4f361f2b-3e94-40a8-e997-6f017c440e52"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: lightning in /usr/local/lib/python3.10/dist-packages (2.0.5)\n","Requirement already satisfied: Jinja2\u003c5.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (3.1.2)\n","Requirement already satisfied: PyYAML\u003c8.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (6.0)\n","Requirement already satisfied: arrow\u003c3.0,\u003e=1.2.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.2.3)\n","Requirement already satisfied: backoff\u003c4.0,\u003e=2.2.1 in /usr/local/lib/python3.10/dist-packages (from lightning) (2.2.1)\n","Requirement already satisfied: beautifulsoup4\u003c6.0,\u003e=4.8.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.11.2)\n","Requirement already satisfied: click\u003c10.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (8.1.4)\n","Requirement already satisfied: croniter\u003c1.5.0,\u003e=1.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.4.1)\n","Requirement already satisfied: dateutils\u003c2.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (0.6.12)\n","Requirement already satisfied: deepdiff\u003c8.0,\u003e=5.7.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (6.3.1)\n","Requirement already satisfied: fastapi\u003c2.0,\u003e=0.92.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (0.100.0)\n","Requirement already satisfied: fsspec\u003c2025.0,\u003e=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2023.6.0)\n","Requirement already satisfied: inquirer\u003c5.0,\u003e=2.10.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (3.1.3)\n","Requirement already satisfied: lightning-cloud\u003e=0.5.37 in /usr/local/lib/python3.10/dist-packages (from lightning) (0.5.37)\n","Requirement already satisfied: lightning-utilities\u003c2.0,\u003e=0.7.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (0.9.0)\n","Requirement already satisfied: numpy\u003c3.0,\u003e=1.17.2 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.22.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lightning) (23.1)\n","Requirement already satisfied: psutil\u003c7.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (5.9.5)\n","Requirement already satisfied: pydantic\u003c2.0.0,\u003e=1.7.4 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.10.11)\n","Requirement already satisfied: python-multipart\u003c2.0,\u003e=0.0.5 in /usr/local/lib/python3.10/dist-packages (from lightning) (0.0.6)\n","Requirement already satisfied: requests\u003c4.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2.27.1)\n","Requirement already satisfied: rich\u003c15.0,\u003e=12.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (13.4.2)\n","Requirement already satisfied: starlette in /usr/local/lib/python3.10/dist-packages (from lightning) (0.27.0)\n","Requirement already satisfied: starsessions\u003c2.0,\u003e=1.2.1 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.3.0)\n","Requirement already satisfied: torch\u003c4.0,\u003e=1.11.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2.0.1+cu118)\n","Requirement already satisfied: torchmetrics\u003c2.0,\u003e=0.7.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.0.1)\n","Requirement already satisfied: tqdm\u003c6.0,\u003e=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.65.0)\n","Requirement already satisfied: traitlets\u003c7.0,\u003e=5.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (5.7.1)\n","Requirement already satisfied: typing-extensions\u003c6.0,\u003e=4.0.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.7.1)\n","Requirement already satisfied: urllib3\u003c4.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.26.16)\n","Requirement already satisfied: uvicorn\u003c2.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (0.23.0)\n","Requirement already satisfied: websocket-client\u003c3.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.6.1)\n","Requirement already satisfied: websockets\u003c13.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (11.0.3)\n","Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (from lightning) (2.0.5)\n","Requirement already satisfied: python-dateutil\u003e=2.7.0 in /usr/local/lib/python3.10/dist-packages (from arrow\u003c3.0,\u003e=1.2.0-\u003elightning) (2.8.2)\n","Requirement already satisfied: soupsieve\u003e1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4\u003c6.0,\u003e=4.8.0-\u003elightning) (2.4.1)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from dateutils\u003c2.0-\u003elightning) (2022.7.1)\n","Requirement already satisfied: ordered-set\u003c4.2.0,\u003e=4.0.2 in /usr/local/lib/python3.10/dist-packages (from deepdiff\u003c8.0,\u003e=5.7.0-\u003elightning) (4.1.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec\u003c2025.0,\u003e=2022.5.0-\u003elightning) (3.8.4)\n","Requirement already satisfied: blessed\u003e=1.19.0 in /usr/local/lib/python3.10/dist-packages (from inquirer\u003c5.0,\u003e=2.10.0-\u003elightning) (1.20.0)\n","Requirement already satisfied: python-editor\u003e=1.0.4 in /usr/local/lib/python3.10/dist-packages (from inquirer\u003c5.0,\u003e=2.10.0-\u003elightning) (1.0.4)\n","Requirement already satisfied: readchar\u003e=3.0.6 in /usr/local/lib/python3.10/dist-packages (from inquirer\u003c5.0,\u003e=2.10.0-\u003elightning) (4.0.5)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2\u003c5.0-\u003elightning) (2.1.3)\n","Requirement already satisfied: pyjwt in /usr/local/lib/python3.10/dist-packages (from lightning-cloud\u003e=0.5.37-\u003elightning) (2.7.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from lightning-cloud\u003e=0.5.37-\u003elightning) (1.16.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests\u003c4.0-\u003elightning) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests\u003c4.0-\u003elightning) (2.0.12)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests\u003c4.0-\u003elightning) (3.4)\n","Requirement already satisfied: markdown-it-py\u003e=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich\u003c15.0,\u003e=12.3.0-\u003elightning) (3.0.0)\n","Requirement already satisfied: pygments\u003c3.0.0,\u003e=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich\u003c15.0,\u003e=12.3.0-\u003elightning) (2.14.0)\n","Requirement already satisfied: anyio\u003c5,\u003e=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette-\u003elightning) (3.7.1)\n","Requirement already satisfied: itsdangerous\u003c3.0.0,\u003e=2.0.1 in /usr/local/lib/python3.10/dist-packages (from starsessions\u003c2.0,\u003e=1.2.1-\u003elightning) (2.1.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch\u003c4.0,\u003e=1.11.0-\u003elightning) (3.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch\u003c4.0,\u003e=1.11.0-\u003elightning) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch\u003c4.0,\u003e=1.11.0-\u003elightning) (3.1)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch\u003c4.0,\u003e=1.11.0-\u003elightning) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-\u003etorch\u003c4.0,\u003e=1.11.0-\u003elightning) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-\u003etorch\u003c4.0,\u003e=1.11.0-\u003elightning) (16.0.6)\n","Requirement already satisfied: h11\u003e=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn\u003c2.0-\u003elightning) (0.14.0)\n","Requirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec\u003c2025.0,\u003e=2022.5.0-\u003elightning) (23.1.0)\n","Requirement already satisfied: multidict\u003c7.0,\u003e=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec\u003c2025.0,\u003e=2022.5.0-\u003elightning) (6.0.4)\n","Requirement already satisfied: async-timeout\u003c5.0,\u003e=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec\u003c2025.0,\u003e=2022.5.0-\u003elightning) (4.0.2)\n","Requirement already satisfied: yarl\u003c2.0,\u003e=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec\u003c2025.0,\u003e=2022.5.0-\u003elightning) (1.9.2)\n","Requirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec\u003c2025.0,\u003e=2022.5.0-\u003elightning) (1.4.0)\n","Requirement already satisfied: aiosignal\u003e=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec\u003c2025.0,\u003e=2022.5.0-\u003elightning) (1.3.1)\n","Requirement already satisfied: sniffio\u003e=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio\u003c5,\u003e=3.4.0-\u003estarlette-\u003elightning) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio\u003c5,\u003e=3.4.0-\u003estarlette-\u003elightning) (1.1.2)\n","Requirement already satisfied: wcwidth\u003e=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed\u003e=1.19.0-\u003einquirer\u003c5.0,\u003e=2.10.0-\u003elightning) (0.2.6)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py\u003e=2.2.0-\u003erich\u003c15.0,\u003e=12.3.0-\u003elightning) (0.1.2)\n","Requirement already satisfied: setuptools\u003e=41.0 in /usr/local/lib/python3.10/dist-packages (from readchar\u003e=3.0.6-\u003einquirer\u003c5.0,\u003e=2.10.0-\u003elightning) (67.7.2)\n","Requirement already satisfied: mpmath\u003e=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch\u003c4.0,\u003e=1.11.0-\u003elightning) (1.3.0)\n"]}],"source":["!pip install lightning"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10618,"status":"ok","timestamp":1689648849841,"user":{"displayName":"ALEJANDRO LANCHO SERRANO","userId":"06980355390280053762"},"user_tz":240},"id":"033b75c5","outputId":"94b920eb-c00c-4d74-c184-15e99104c8b7"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch       : 2.0.1+cu118\n","transformers: 4.30.2\n","datasets    : 2.13.1\n","lightning   : 2.0.5\n","\n","conda environment: n/a\n","\n"]}],"source":["%load_ext watermark\n","%watermark --conda -p torch,transformers,datasets,lightning"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1059,"status":"ok","timestamp":1689648850891,"user":{"displayName":"ALEJANDRO LANCHO SERRANO","userId":"06980355390280053762"},"user_tz":240},"id":"h3InsktvriCr","outputId":"05518aba-229a-4032-a96e-3a0899e627ae"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')\n","import sys\n","sys.path.append('/content/gdrive/MyDrive/lightning_ai/dl-fundamentals_lighning_ai/unit08-large-language-models/exercises/tmp')\n","import os\n","os.chdir(globals()['_dh'][0])\n","os.chdir('..')\n","os.chdir('./content/gdrive/MyDrive/lightning_ai/dl-fundamentals_lighning_ai/unit08-large-language-models/exercises/tmp')"]},{"cell_type":"markdown","metadata":{"id":"09213821-b2b4-402e-adf8-7c7fe4ec57cb"},"source":["# 1 Loading the dataset into DataFrames"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e39e2228-5f0b-4fb9-b762-df26c2052b45"},"outputs":[],"source":["import os.path as op\n","\n","from datasets import load_dataset\n","\n","import lightning as L\n","from lightning.pytorch.loggers import CSVLogger\n","from lightning.pytorch.callbacks import ModelCheckpoint\n","\n","import numpy as np\n","import pandas as pd\n","import torch\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","from local_dataset_utilities import download_dataset, load_dataset_into_to_dataframe, partition_dataset\n","from local_dataset_utilities import IMDBDataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fb31ac90-9e3a-41d0-baf1-8e613043924b"},"outputs":[],"source":["# download_dataset()\n","\n","# df = load_dataset_into_to_dataframe()\n","# partition_dataset(df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"221f30a1-b433-4304-a18d-8d03abd42b58"},"outputs":[],"source":["df_train = pd.read_csv(\"train.csv\")\n","df_val = pd.read_csv(\"val.csv\")\n","df_test = pd.read_csv(\"test.csv\")"]},{"cell_type":"markdown","metadata":{"id":"876736c1-ae27-491c-850b-050507fa02b5"},"source":["# 2 Tokenization and Numericalization"]},{"cell_type":"markdown","metadata":{"id":"afe0cca0-bac4-49ed-982c-14c998e578d1"},"source":["**Load the dataset via `load_dataset`**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337},"executionInfo":{"elapsed":563,"status":"ok","timestamp":1689648856469,"user":{"displayName":"ALEJANDRO LANCHO SERRANO","userId":"06980355390280053762"},"user_tz":240},"id":"a1aa66c7","outputId":"0d66ad80-b32a-41d7-d787-9f1022587af2"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:datasets.builder:Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-6d9636297ad55cb1/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"065581b788254b81b3b48356bdafcae3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['index', 'text', 'label'],\n","        num_rows: 35000\n","    })\n","    validation: Dataset({\n","        features: ['index', 'text', 'label'],\n","        num_rows: 5000\n","    })\n","    test: Dataset({\n","        features: ['index', 'text', 'label'],\n","        num_rows: 10000\n","    })\n","})\n"]}],"source":["imdb_dataset = load_dataset(\n","    \"csv\",\n","    data_files={\n","        \"train\": \"train.csv\",\n","        \"validation\": \"val.csv\",\n","        \"test\": \"test.csv\",\n","    },\n",")\n","\n","print(imdb_dataset)"]},{"cell_type":"markdown","metadata":{"id":"8b201159-f3fa-4649-8076-eff8bc5535d3"},"source":["**Tokenize the dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":160,"status":"ok","timestamp":1689648856628,"user":{"displayName":"ALEJANDRO LANCHO SERRANO","userId":"06980355390280053762"},"user_tz":240},"id":"17e03ece","outputId":"24abed9f-0ada-4e30-89f5-297b7aa7631c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Steve Biko was a black activist who tried to resist the white minority governed South Africa in much the same way as Gandhi tried to resist the British empire's colonialism in India. Richard Attenborough's film Cry Freedom is not about Biko or Apartheid as much as it is about Donald Woods, the white liberal newspaper editor who risked his life trying to tell Biko's story. The film has a jarring point of view switch after Biko dies in prison from tortuous behavior at the hands of South African \"police\". Woods, played by Kevin Kline, must choose whether to do the right thing and flee the country to publish books about Biko or allow his wife, played by Penelope Wilton, to pressure him into forgetting about the books. In that case, Biko dies in vain. What begins as a life-changing friendship between Biko and Woods degenerates into a standard by the numbers escape over the border yarn after Biko's death. Oscar-nominated Denzel Washington is good in only his fourth film as Biko, but something is wrong in a film that tries to depict the struggles of Apartheid by focusing more on the trials of a white family for more than half the film. Attenborough would have served his topic better by focusing on Biko's rise to prominence instead of beginning where Biko befriended Woods. Perhaps a black actor in a leading role in a 2 1/2 hour film wasn't exactly conducive to big box office, but the film was a tremendous box office flop anyway. Film politics aside, the film still entertains and sends a message or two, albeit, in PG-sanitized fashion. *** of 4 stars.\n"]}],"source":["print(imdb_dataset['train'][1]['text'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":939,"status":"ok","timestamp":1689648857566,"user":{"displayName":"ALEJANDRO LANCHO SERRANO","userId":"06980355390280053762"},"user_tz":240},"id":"5ea762ba","outputId":"c49e7992-d3ff-48b7-cda9-c66df1e1b668"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tokenizer input max length: 512\n","Tokenizer vocabulary size: 50265\n"]}],"source":["from transformers import AutoTokenizer\n","\n","# tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\") # Default from course\n","# tokenizer = AutoTokenizer.from_pretrained(\"deepset/deberta-v3-base-injection\") # Too big for Colab\n","# tokenizer = AutoTokenizer.from_pretrained(\"SamLowe/roberta-base-go_emotions\")\n","tokenizer = AutoTokenizer.from_pretrained(\"siebert/sentiment-roberta-large-english\")\n","# tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n","\n","print(\"Tokenizer input max length:\", tokenizer.model_max_length)\n","print(\"Tokenizer vocabulary size:\", tokenizer.vocab_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8432c15c"},"outputs":[],"source":["def tokenize_text(batch):\n","    return tokenizer(batch[\"text\"], truncation=True, padding=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":105},"id":"0bb392cf","outputId":"6ef5fe86-1e6f-4c6e-ea2a-2d4465ceb1dc"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-6d9636297ad55cb1/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-e1f6c0a54cd4b0c6.arrow\n","WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-6d9636297ad55cb1/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-3d2f53f7b5b12b65.arrow\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4ed06e3126b048e5b557f0c58537ccd6","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/10000 [00:00\u003c?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["imdb_tokenized = imdb_dataset.map(tokenize_text, batched=True, batch_size=None)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"6d4103c3"},"outputs":[],"source":["del imdb_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"89ef894c-978f-47f2-9d61-cb6a9f38e745"},"outputs":[],"source":["imdb_tokenized.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"0ea67091-aeb7-46c1-871f-638ce58d8a0e"},"outputs":[],"source":["import os\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""]},{"cell_type":"markdown","metadata":{"id":"7ff16488-abe6-48af-9b03-868b457b0ea3"},"source":["# 3 Set Up DataLoaders"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"0807b068-7d8f-4055-a26a-177e07dea4c7"},"outputs":[],"source":["from torch.utils.data import DataLoader, Dataset\n","\n","\n","class IMDBDataset(Dataset):\n","    def __init__(self, dataset_dict, partition_key=\"train\"):\n","        self.partition = dataset_dict[partition_key]\n","\n","    def __getitem__(self, index):\n","        return self.partition[index]\n","\n","    def __len__(self):\n","        return self.partition.num_rows"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"90cb08f3-ef77-4351-8b19-42d99dd24f98","outputId":"c0690dec-b14d-45dc-e883-e30de01bfc8c"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}],"source":["train_dataset = IMDBDataset(imdb_tokenized, partition_key=\"train\")\n","val_dataset = IMDBDataset(imdb_tokenized, partition_key=\"validation\")\n","test_dataset = IMDBDataset(imdb_tokenized, partition_key=\"test\")\n","\n","train_loader = DataLoader(\n","    dataset=train_dataset,\n","    batch_size=12,\n","    shuffle=True,\n","    num_workers=4\n",")\n","\n","val_loader = DataLoader(\n","    dataset=val_dataset,\n","    batch_size=12,\n","    num_workers=4\n",")\n","\n","test_loader = DataLoader(\n","    dataset=test_dataset,\n","    batch_size=12,\n","    num_workers=4\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"BM-GoJaN2-q6","outputId":"e20fbbdc-fa95-4bae-fefd-f5a773d08761"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset({\n","    features: ['index', 'text', 'label', 'input_ids', 'attention_mask'],\n","    num_rows: 35000\n","})\n"]}],"source":["print(train_loader.dataset.partition)"]},{"cell_type":"markdown","metadata":{"id":"78e774ab-45a0-4c48-ad61-a3d0e1927ef4"},"source":["# 4 Initializing DistilBERT"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"PbwXjz1b_i6h"},"outputs":[],"source":["from transformers import AutoModelForSequenceClassification"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"dc28ddbe-1a96-4c24-9f5c-40ffdca4a572"},"outputs":[],"source":["\n","\n","# model = AutoModelForSequenceClassification.from_pretrained(\n","#     \"distilbert-base-uncased\", num_labels=2)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"X7YiNd74yUNu"},"source":["### Intializing a different model:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"LEFZOHy30w74","outputId":"0454a23c-c633-41a4-bc7c-732521967480"},"outputs":[{"data":{"text/plain":["RobertaForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=28, bias=True)\n","  )\n",")"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["\n","model = AutoModelForSequenceClassification.from_pretrained(\"SamLowe/roberta-base-go_emotions\")\n","\n","model\n","# model.classifier.out_proj = torch.nn.Linear(in_features=28, out_features=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"pWByLvX6MbmC"},"outputs":[],"source":["model.classifier.out_proj = torch.nn.Linear(in_features=768, out_features=2)\n","# model.classifier.out_proj = torch.nn.Sequential(\n","#     model.classifier.out_proj,\n","#     torch.nn.Flatten(start_dim=1)\n","# )\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"8C1bX9ue_gob"},"outputs":[],"source":["# model = AutoModelForSequenceClassification.from_pretrained(\n","#     \"siebert/sentiment-roberta-large-english\", num_labels=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ozndJjZWBEo5"},"outputs":[],"source":["# model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\", num_labels =2)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"htC1IPM17INx","outputId":"581a534e-7bd7-4720-f9a3-217205b6d2fa"},"outputs":[{"data":{"text/plain":["RobertaForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n","  )\n",")"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"maR6WO7zyR35"},"outputs":[],"source":["# # Load model directly. Tokenizing too big with this model\n","# from transformers import AutoModelForSequenceClassification\n","\n","# model = AutoModelForSequenceClassification.from_pretrained(\"deepset/deberta-v3-base-injection\")\n"]},{"cell_type":"markdown","metadata":{"id":"def1cf25-0a7d-4bb2-9419-b7a8fe1c1eab"},"source":["## 5 Finetuning"]},{"cell_type":"markdown","metadata":{"id":"534f7a59-2c86-4895-ad7c-2cdd675b003a"},"source":["**Wrap in LightningModule for Training**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"9f2c474d"},"outputs":[],"source":["import lightning as L\n","import torch\n","import torchmetrics\n","\n","\n","class LightningModel(L.LightningModule):\n","    def __init__(self, model, learning_rate=5e-5):\n","        super().__init__()\n","\n","        self.learning_rate = learning_rate\n","        self.model = model\n","\n","        self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2)\n","        self.test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2)\n","\n","    def forward(self, input_ids, attention_mask, labels):\n","        return self.model(input_ids, attention_mask=attention_mask, labels=labels)\n","\n","    def training_step(self, batch, batch_idx):\n","        outputs = self(batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"],\n","                       labels=batch[\"label\"])\n","        self.log(\"train_loss\", outputs[\"loss\"])\n","        return outputs[\"loss\"]  # this is passed to the optimizer for training\n","\n","    def validation_step(self, batch, batch_idx):\n","        outputs = self(batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"],\n","                       labels=batch[\"label\"])\n","        self.log(\"val_loss\", outputs[\"loss\"], prog_bar=True)\n","\n","        logits = outputs[\"logits\"]\n","        predicted_labels = torch.argmax(logits, 1)\n","        self.val_acc(predicted_labels, batch[\"label\"])\n","        self.log(\"val_acc\", self.val_acc, prog_bar=True)\n","\n","    def test_step(self, batch, batch_idx):\n","        outputs = self(batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"],\n","                       labels=batch[\"label\"])\n","\n","        logits = outputs[\"logits\"]\n","        predicted_labels = torch.argmax(logits, 1)\n","        self.test_acc(predicted_labels, batch[\"label\"])\n","        self.log(\"accuracy\", self.test_acc, prog_bar=True)\n","\n","    def configure_optimizers(self):\n","        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n","        return optimizer\n","\n","\n","lightning_model = LightningModel(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"e6dab813-e1fc-47cd-87a1-5eb8070699c6"},"outputs":[],"source":["from lightning.pytorch.callbacks import ModelCheckpoint\n","from lightning.pytorch.loggers import CSVLogger\n","\n","\n","callbacks = [\n","    ModelCheckpoint(\n","        save_top_k=1, mode=\"max\", monitor=\"val_acc\"\n","    )  # save top 1 model\n","]\n","logger = CSVLogger(save_dir=\"logs/\", name=\"my-model\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":698},"id":"492aa043-02da-459e-a266-091b34254ac6"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py:508: UserWarning: You passed `Trainer(accelerator='cpu', precision='16-mixed')` but AMP with fp16 is not supported on CPU. Using `precision='bf16-mixed'` instead.\n","  rank_zero_warn(\n","INFO: Using bfloat16 Automatic Mixed Precision (AMP)\n","INFO:lightning.pytorch.utilities.rank_zero:Using bfloat16 Automatic Mixed Precision (AMP)\n","INFO: GPU available: False, used: False\n","INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n","INFO: TPU available: False, using: 0 TPU cores\n","INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO: IPU available: False, using: 0 IPUs\n","INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO: HPU available: False, using: 0 HPUs\n","INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO: \n","  | Name     | Type                             | Params\n","--------------------------------------------------------------\n","0 | model    | RobertaForSequenceClassification | 124 M \n","1 | val_acc  | MulticlassAccuracy               | 0     \n","2 | test_acc | MulticlassAccuracy               | 0     \n","--------------------------------------------------------------\n","124 M     Trainable params\n","0         Non-trainable params\n","124 M     Total params\n","498.589   Total estimated model params size (MB)\n","INFO:lightning.pytorch.callbacks.model_summary:\n","  | Name     | Type                             | Params\n","--------------------------------------------------------------\n","0 | model    | RobertaForSequenceClassification | 124 M \n","1 | val_acc  | MulticlassAccuracy               | 0     \n","2 | test_acc | MulticlassAccuracy               | 0     \n","--------------------------------------------------------------\n","124 M     Trainable params\n","0         Non-trainable params\n","124 M     Total params\n","498.589   Total estimated model params size (MB)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"90e3da5242504658a01f98b99e141f04","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"ename":"ValueError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-31-14a978ee7112\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 11\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 11\u001b[0;31m trainer.fit(model=lightning_model,\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             val_dataloaders=val_loader)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_unwrap_optimized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lightning_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 529\u001b[0;31m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    530\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 42\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    566\u001b[0m             \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         )\n\u001b[0;32m--\u003e 568\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    971\u001b[0m         \u001b[0;31m# RUN THE TRAINER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 973\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0misolate_rng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1014\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m             \u001b[0;31m# run eval step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1043\u001b[0;31m             \u001b[0mval_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m             \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_callback_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"on_sanity_check_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/utilities.py\u001b[0m in \u001b[0;36m_decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mcontext_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcontext_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 177\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mloop_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_decorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/evaluation_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0mprevious_dataloader_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0;31m# run step hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 115\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0;31m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/evaluation_loop.py\u001b[0m in \u001b[0;36m_evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mhook_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"test_step\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 375\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_strategy_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstep_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_progress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincrement_processed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/call.py\u001b[0m in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Strategy]{trainer.strategy.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 291\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;31m# restore current_fx when nested context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/strategies/strategy.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValidationStep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 379\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u003e\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSTEP_OUTPUT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m\u003cipython-input-29-01fff7b596ef\u003e\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 26\u001b[0;31m         outputs = self(batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"],\n\u001b[0m\u001b[1;32m     27\u001b[0m                        labels=batch[\"label\"])        \n\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprog_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-\u003e 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m\u003cipython-input-29-01fff7b596ef\u003e\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, labels)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 17\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-\u003e 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1251\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"multi_label_classification\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m                 \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1253\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-\u003e 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u003e\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 720\u001b[0;31m         return F.binary_cross_entropy_with_logits(input, target,\n\u001b[0m\u001b[1;32m    721\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   3161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3162\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 3163\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([12])) must be the same as input size (torch.Size([12, 2]))"]}],"source":["trainer = L.Trainer(\n","    max_epochs=3,\n","    callbacks=callbacks,\n","    accelerator=\"cpu\",\n","    precision=\"16-mixed\",\n","    devices=1,\n","    logger=logger,\n","    log_every_n_steps=10,\n",")\n","\n","trainer.fit(model=lightning_model,\n","            train_dataloaders=train_loader,\n","            val_dataloaders=val_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d795778a-70d2-4b04-96fb-598eccbcd1be"},"outputs":[],"source":["trainer.test(lightning_model, dataloaders=train_loader, ckpt_path=\"best\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"10ca0af1-106e-4ef7-9793-478d580af827"},"outputs":[],"source":["trainer.test(lightning_model, dataloaders=val_loader, ckpt_path=\"best\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eeb92de4-d483-4627-b9f3-f0bba0cddd9c"},"outputs":[],"source":["trainer.test(lightning_model, dataloaders=test_loader, ckpt_path=\"best\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3515de14-6243-4cec-a554-e55e8d10dcc4"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d34b9bce-b269-420a-8533-cff862e0b85d"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"widgets":{"application/vnd.jupyter.widget-state+json":{"065581b788254b81b3b48356bdafcae3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4f7b2bfe7c2b439088bde43320424a97","IPY_MODEL_68c07609aae84b929a04550bd5d16104","IPY_MODEL_1c6ffe75a4cc4946a7bb3bd2fa695b5f"],"layout":"IPY_MODEL_f384021c48384a19ba21d56adf35d72f"}},"17f0313540fd479dae99b97b9ebb2d15":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c6ffe75a4cc4946a7bb3bd2fa695b5f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba7870c2c6704b5ea5e9d86eee2658d4","placeholder":"​","style":"IPY_MODEL_ad3fa6b1093f4383995b24a3e70a2438","value":" 3/3 [00:00\u0026lt;00:00,  8.39it/s]"}},"3e5071c44b5a408c8256787a2c27a028":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4702821660ff4ef5bd7f57a912bfafd9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_17f0313540fd479dae99b97b9ebb2d15","placeholder":"​","style":"IPY_MODEL_5800e44a0f65452d9ffdbd2a9cdf7aa9","value":" 0/10000 [00:00\u0026lt;?, ? examples/s]"}},"4ed06e3126b048e5b557f0c58537ccd6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_54a56c46de9e49489f2e27d20ef687a0","IPY_MODEL_51af532e1b1d48928777e5dc0c786d9c","IPY_MODEL_4702821660ff4ef5bd7f57a912bfafd9"],"layout":"IPY_MODEL_3e5071c44b5a408c8256787a2c27a028"}},"4f7b2bfe7c2b439088bde43320424a97":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aada6b8eec144574b6affcf4e1cbde8f","placeholder":"​","style":"IPY_MODEL_54e99a409f554a07b157d638ac4c54b6","value":"100%"}},"51af532e1b1d48928777e5dc0c786d9c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_b084a48b7c7a433098827408461c2825","max":10000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a5615a7c515543bf9d2bd3d53f009756","value":0}},"54a56c46de9e49489f2e27d20ef687a0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3e07f8c4f4a42be9f260ba84afee66d","placeholder":"​","style":"IPY_MODEL_59d083b829af4d27a1bac7176ef9ccdf","value":"Map:   0%"}},"54e99a409f554a07b157d638ac4c54b6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5800e44a0f65452d9ffdbd2a9cdf7aa9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"59d083b829af4d27a1bac7176ef9ccdf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68c07609aae84b929a04550bd5d16104":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_da335b902e4c435f8a1822d19196229b","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9ea252fe27744cc796c685f48e1b1da7","value":3}},"9ea252fe27744cc796c685f48e1b1da7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a3e07f8c4f4a42be9f260ba84afee66d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5615a7c515543bf9d2bd3d53f009756":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aada6b8eec144574b6affcf4e1cbde8f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad3fa6b1093f4383995b24a3e70a2438":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b084a48b7c7a433098827408461c2825":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba7870c2c6704b5ea5e9d86eee2658d4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da335b902e4c435f8a1822d19196229b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f384021c48384a19ba21d56adf35d72f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":5}